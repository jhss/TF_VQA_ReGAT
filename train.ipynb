{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23223,
     "status": "ok",
     "timestamp": 1672057760308,
     "user": {
      "displayName": "hhog ssap",
      "userId": "13037467103569678500"
     },
     "user_tz": -540
    },
    "id": "wF09vUTs7Pez",
    "outputId": "2072cef0-6613-4409-ecb5-a5fbc774fd14"
   },
   "outputs": [],
   "source": [
    "!sudo cp /usr/lib/python3/dist-packages/tensorflow/libcudnn* /usr/lib/x86_64-linux-gnu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2K3p8WYrkqYZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "2023-01-03 13:25:26.683250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:26.723881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:26.724253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:27.239952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:27.240192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:27.240379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:27.240528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /device:GPU:0 with 46694 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:00.0, compute capability: 8.6\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7056537450259576060\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 48962928640\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2998306216550413810\n",
      "physical_device_desc: \"device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "[DEBUG] HELLO main main main main\n",
      "[DEBUG] args.data_folder:  ../VQA_ReGAT/data\n",
      "loading dictionary from ../RaGAT/data/glove/dictionary.pkl\n",
      "loading features from h5 file ../RaGAT/data//Bottom-up-features-adaptive/val.hdf5\n",
      "Setting semantic adj matrix to None...\n",
      "Setting spatial adj matrix to None...\n",
      "loading features from h5 file ../RaGAT/data//Bottom-up-features-adaptive/train.hdf5\n",
      "Setting semantic adj matrix to None...\n",
      "Setting spatial adj matrix to None...\n",
      "Building ReGAT model with implicit and butd fusion method\n",
      "2023-01-03 13:25:50.859698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:50.859972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:50.860148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:50.860485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:50.860672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:50.860841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:50.861106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:50.861281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-03 13:25:50.861410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46694 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:00.0, compute capability: 8.6\n",
      "[DEBUG] linear1:  <model.fc.FullyConnected object at 0x7f451f9b8d90>\n",
      "[DEBUG] implicit out_dim:  1024\n",
      "In ImplicitRelationEncoder, num of graph propogate steps: 1 residual_connection: True\n",
      "[DEBUG] v2out v_dim, out_dim:  2048 1024\n",
      "[DEBUG] train_dset:  19901 2048 3129\n",
      "[DEBUG] val_dset:  19901 2048 3129\n",
      "[DEBUG] N:  19901\n",
      "[DEBUG] vqa dic length:  19901\n",
      "len inds:  2\n",
      "len inds[0]:  39189402  len inds[1]:  39189402\n",
      "[DEBUG] vg dic length:  28333\n",
      "[DEBUG] tfidf.dtype:  <dtype: 'float32'>\n",
      "[DEBUG] dictionary len:  19901\n",
      "[DEBUG] dictionary.idx2word len:  28333\n",
      "embedding dim is 300\n",
      "[DEBUG] glove_Weights:  [[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.12842   0.3135    0.2269   ... -0.027753  0.3113    0.40595 ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
      "tf-idf stochastic matrix (19901 x 28333) is generated.\n",
      "[DEUBG] weight_init.shape:  (19901, 300)\n",
      "[DEBUG] weight_init dtype:  <dtype: 'float32'>  pad dtpye:  <dtype: 'float32'>\n",
      "[DEBUG] get_weights.shape:  (19902, 300)\n",
      "[DEBUG] get_weights length:  1\n",
      "[DEBUG] get_weights length:  <class 'list'>\n",
      "[DE]\n",
      "[DEBUG] CLEAR\n",
      "[DEBUG] Before concat:  (19901, 300)\n",
      "[DEBUG] tf_weights.shape:  (8432, 300)\n",
      "[DEBUG] After concat weight_init.shape:  (28333, 300)\n",
      "[DEBUG] main func val_dset len:  3349\n",
      "[DEBUG] total train data:  443757\n",
      "[DEBUG] lr default:  0.001\n",
      "[DEBUG] weight decay off\n",
      "optim: adamax lr=0.0009, decay_step=2, decay_rate=0.25,grad_clip=0.25\n",
      "\n",
      "Epoch: 0. Reducing Learning Rate from 0.0008999999845400453 to 0.0009\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 0, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2023-01-03 13:27:06.398002: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8303\n",
      "2023-01-03 13:27:06.604905: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-01-03 13:27:07.102780: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0xa815f720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-01-03 13:27:07.102865: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-01-03 13:27:09.362876: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-01-03 13:27:12.678585: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Epoch [1][499/1733] Elapsed 7m 24s (remain 18m 15s) Loss: 5.60743(18.80284, 0.00179)\n",
      "Epoch [1][999/1733] Elapsed 12m 22s (remain 9m 4s) Loss: 4.63458(12.05695, 0.00148)\n",
      "Epoch [1][1499/1733] Elapsed 17m 23s (remain 2m 42s) Loss: 4.73161(9.57170, 0.00151)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [1][499/3349] Elapsed 1m 15s (remain 7m 10s) Loss: 0.00156(0.00140)\n",
      "Epoch [1][999/3349] Elapsed 2m 5s (remain 4m 54s) Loss: 0.00148(0.00139)\n",
      "Epoch [1][1499/3349] Elapsed 2m 53s (remain 3m 34s) Loss: 0.00146(0.00139)\n",
      "Epoch [1][1999/3349] Elapsed 3m 42s (remain 2m 30s) Loss: 0.00133(0.00139)\n",
      "Epoch [1][2499/3349] Elapsed 4m 31s (remain 1m 32s) Loss: 0.00134(0.00139)\n",
      "Epoch [1][2999/3349] Elapsed 5m 20s (remain 0m 37s) Loss: 0.00124(0.00138)\n",
      "[DEBUG] train_score: 0.3834 eval_score: 0.4675\n",
      "\n",
      "Epoch: 1. Reducing Learning Rate from 0.0008999999845400453 to 0.0009\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 1, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [2][499/1733] Elapsed 5m 4s (remain 12m 30s) Loss: 3.81043(4.06707, 0.00122)\n",
      "Epoch [2][999/1733] Elapsed 9m 55s (remain 7m 16s) Loss: 3.93530(3.98293, 0.00126)\n",
      "Epoch [2][1499/1733] Elapsed 14m 45s (remain 2m 17s) Loss: 3.76250(3.91170, 0.00120)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [2][499/3349] Elapsed 0m 50s (remain 4m 45s) Loss: 0.00100(0.00122)\n",
      "Epoch [2][999/3349] Elapsed 1m 37s (remain 3m 48s) Loss: 0.00118(0.00122)\n",
      "Epoch [2][1499/3349] Elapsed 2m 24s (remain 2m 58s) Loss: 0.00126(0.00122)\n",
      "Epoch [2][1999/3349] Elapsed 3m 13s (remain 2m 10s) Loss: 0.00131(0.00122)\n",
      "Epoch [2][2499/3349] Elapsed 4m 4s (remain 1m 23s) Loss: 0.00168(0.00122)\n",
      "Epoch [2][2999/3349] Elapsed 4m 55s (remain 0m 34s) Loss: 0.00116(0.00122)\n",
      "[DEBUG] train_score: 0.5226 eval_score: 0.5352\n",
      "\n",
      "Epoch: 2. Reducing Learning Rate from 0.0008999999845400453 to 0.00108\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 2, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [3][499/1733] Elapsed 5m 2s (remain 12m 25s) Loss: 3.45742(3.52836, 0.00110)\n",
      "Epoch [3][999/1733] Elapsed 9m 59s (remain 7m 19s) Loss: 3.59330(3.50567, 0.00115)\n",
      "Epoch [3][1499/1733] Elapsed 14m 53s (remain 2m 18s) Loss: 3.27346(3.48718, 0.00105)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [3][499/3349] Elapsed 0m 50s (remain 4m 45s) Loss: 0.00119(0.00114)\n",
      "Epoch [3][999/3349] Elapsed 1m 39s (remain 3m 53s) Loss: 0.00098(0.00114)\n",
      "Epoch [3][1499/3349] Elapsed 2m 30s (remain 3m 5s) Loss: 0.00137(0.00113)\n",
      "Epoch [3][1999/3349] Elapsed 3m 20s (remain 2m 15s) Loss: 0.00118(0.00113)\n",
      "Epoch [3][2499/3349] Elapsed 4m 11s (remain 1m 25s) Loss: 0.00100(0.00114)\n",
      "Epoch [3][2999/3349] Elapsed 5m 2s (remain 0m 35s) Loss: 0.00132(0.00114)\n",
      "[DEBUG] train_score: 0.5788 eval_score: 0.5851\n",
      "\n",
      "Epoch: 3. Reducing Learning Rate from 0.00107999995816499 to 0.00117\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 3, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [4][499/1733] Elapsed 5m 1s (remain 12m 24s) Loss: 2.87965(3.22013, 0.00092)\n",
      "Epoch [4][999/1733] Elapsed 9m 53s (remain 7m 15s) Loss: 2.98149(3.21203, 0.00095)\n",
      "Epoch [4][1499/1733] Elapsed 14m 47s (remain 2m 17s) Loss: 3.09039(3.20882, 0.00099)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [4][499/3349] Elapsed 0m 51s (remain 4m 52s) Loss: 0.00103(0.00112)\n",
      "Epoch [4][999/3349] Elapsed 1m 42s (remain 3m 59s) Loss: 0.00093(0.00111)\n",
      "Epoch [4][1499/3349] Elapsed 2m 31s (remain 3m 7s) Loss: 0.00134(0.00111)\n",
      "Epoch [4][1999/3349] Elapsed 3m 23s (remain 2m 17s) Loss: 0.00118(0.00112)\n",
      "Epoch [4][2499/3349] Elapsed 4m 14s (remain 1m 26s) Loss: 0.00128(0.00112)\n",
      "Epoch [4][2999/3349] Elapsed 5m 5s (remain 0m 35s) Loss: 0.00118(0.00111)\n",
      "[DEBUG] train_score: 0.6214 eval_score: 0.5993\n",
      "\n",
      "Epoch: 4. Reducing Learning Rate from 0.0011699999449774623 to 0.0012599999999999998\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 4, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [5][499/1733] Elapsed 4m 59s (remain 12m 17s) Loss: 3.11459(2.97823, 0.00100)\n",
      "Epoch [5][999/1733] Elapsed 9m 52s (remain 7m 14s) Loss: 2.94222(2.99442, 0.00094)\n",
      "Epoch [5][1499/1733] Elapsed 14m 48s (remain 2m 18s) Loss: 2.65374(3.00482, 0.00085)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [5][499/3349] Elapsed 0m 52s (remain 4m 56s) Loss: 0.00100(0.00109)\n",
      "Epoch [5][999/3349] Elapsed 1m 42s (remain 4m 0s) Loss: 0.00103(0.00109)\n",
      "Epoch [5][1499/3349] Elapsed 2m 32s (remain 3m 8s) Loss: 0.00134(0.00109)\n",
      "Epoch [5][1999/3349] Elapsed 3m 23s (remain 2m 17s) Loss: 0.00126(0.00109)\n",
      "Epoch [5][2499/3349] Elapsed 4m 15s (remain 1m 26s) Loss: 0.00138(0.00109)\n",
      "Epoch [5][2999/3349] Elapsed 5m 5s (remain 0m 35s) Loss: 0.00092(0.00109)\n",
      "[DEBUG] train_score: 0.6527 eval_score: 0.6153\n",
      "\n",
      "Epoch: 5. Reducing Learning Rate from 0.0012600000482052565 to 0.0009450000361539423\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 5, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [6][499/1733] Elapsed 4m 54s (remain 12m 5s) Loss: 2.74294(2.72791, 0.00088)\n",
      "Epoch [6][999/1733] Elapsed 9m 43s (remain 7m 7s) Loss: 2.49858(2.73600, 0.00080)\n",
      "Epoch [6][1499/1733] Elapsed 14m 39s (remain 2m 16s) Loss: 2.91840(2.74512, 0.00093)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [6][499/3349] Elapsed 0m 51s (remain 4m 51s) Loss: 0.00115(0.00108)\n",
      "Epoch [6][999/3349] Elapsed 1m 40s (remain 3m 55s) Loss: 0.00093(0.00108)\n",
      "Epoch [6][1499/3349] Elapsed 2m 29s (remain 3m 4s) Loss: 0.00104(0.00108)\n",
      "Epoch [6][1999/3349] Elapsed 3m 18s (remain 2m 13s) Loss: 0.00129(0.00108)\n",
      "Epoch [6][2499/3349] Elapsed 4m 10s (remain 1m 25s) Loss: 0.00119(0.00108)\n",
      "Epoch [6][2999/3349] Elapsed 5m 0s (remain 0m 34s) Loss: 0.00087(0.00108)\n",
      "[DEBUG] train_score: 0.6930 eval_score: 0.6256\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 6, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [7][499/1733] Elapsed 4m 52s (remain 12m 1s) Loss: 2.72328(2.55022, 0.00087)\n",
      "Epoch [7][999/1733] Elapsed 9m 45s (remain 7m 9s) Loss: 2.36438(2.57077, 0.00076)\n",
      "Epoch [7][1499/1733] Elapsed 14m 38s (remain 2m 16s) Loss: 2.89261(2.58817, 0.00092)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [7][499/3349] Elapsed 0m 51s (remain 4m 50s) Loss: 0.00108(0.00109)\n",
      "Epoch [7][999/3349] Elapsed 1m 41s (remain 3m 57s) Loss: 0.00119(0.00108)\n",
      "Epoch [7][1499/3349] Elapsed 2m 35s (remain 3m 11s) Loss: 0.00107(0.00108)\n",
      "Epoch [7][1999/3349] Elapsed 3m 26s (remain 2m 18s) Loss: 0.00114(0.00109)\n",
      "Epoch [7][2499/3349] Elapsed 4m 15s (remain 1m 26s) Loss: 0.00123(0.00109)\n",
      "Epoch [7][2999/3349] Elapsed 5m 3s (remain 0m 35s) Loss: 0.00085(0.00109)\n",
      "[DEBUG] train_score: 0.7185 eval_score: 0.6293\n",
      "\n",
      "Epoch: 7. Reducing Learning Rate from 0.0009450000361539423 to 0.000708750041667372\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 7, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [8][499/1733] Elapsed 4m 48s (remain 11m 51s) Loss: 1.98927(2.35179, 0.00064)\n",
      "Epoch [8][999/1733] Elapsed 9m 39s (remain 7m 4s) Loss: 2.22999(2.37580, 0.00071)\n",
      "Epoch [8][1499/1733] Elapsed 14m 31s (remain 2m 15s) Loss: 2.40964(2.38788, 0.00077)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [8][499/3349] Elapsed 0m 53s (remain 5m 2s) Loss: 0.00123(0.00110)\n",
      "Epoch [8][999/3349] Elapsed 1m 44s (remain 4m 4s) Loss: 0.00103(0.00110)\n",
      "Epoch [8][1499/3349] Elapsed 2m 34s (remain 3m 10s) Loss: 0.00130(0.00109)\n",
      "Epoch [8][1999/3349] Elapsed 3m 24s (remain 2m 17s) Loss: 0.00107(0.00109)\n",
      "Epoch [8][2499/3349] Elapsed 4m 13s (remain 1m 26s) Loss: 0.00122(0.00109)\n",
      "Epoch [8][2999/3349] Elapsed 5m 3s (remain 0m 35s) Loss: 0.00109(0.00109)\n",
      "[DEBUG] train_score: 0.7517 eval_score: 0.6336\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 8, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [9][499/1733] Elapsed 4m 59s (remain 12m 18s) Loss: 2.29788(2.22015, 0.00073)\n",
      "Epoch [9][999/1733] Elapsed 9m 52s (remain 7m 14s) Loss: 2.27899(2.24577, 0.00073)\n",
      "Epoch [9][1499/1733] Elapsed 14m 46s (remain 2m 17s) Loss: 2.16843(2.26124, 0.00069)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [9][499/3349] Elapsed 0m 51s (remain 4m 51s) Loss: 0.00145(0.00112)\n",
      "Epoch [9][999/3349] Elapsed 1m 41s (remain 3m 58s) Loss: 0.00104(0.00111)\n",
      "Epoch [9][1499/3349] Elapsed 2m 32s (remain 3m 8s) Loss: 0.00145(0.00111)\n",
      "Epoch [9][1999/3349] Elapsed 3m 23s (remain 2m 17s) Loss: 0.00114(0.00111)\n",
      "Epoch [9][2499/3349] Elapsed 4m 13s (remain 1m 26s) Loss: 0.00102(0.00111)\n",
      "Epoch [9][2999/3349] Elapsed 5m 2s (remain 0m 35s) Loss: 0.00130(0.00111)\n",
      "[DEBUG] train_score: 0.7726 eval_score: 0.6333\n",
      "\n",
      "Epoch: 9. Reducing Learning Rate from 0.000708750041667372 to 0.0005315625458024442\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 9, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [10][499/1733] Elapsed 4m 49s (remain 11m 54s) Loss: 2.23551(2.07432, 0.00071)\n",
      "Epoch [10][999/1733] Elapsed 9m 40s (remain 7m 5s) Loss: 2.05217(2.08801, 0.00066)\n",
      "Epoch [10][1499/1733] Elapsed 14m 32s (remain 2m 15s) Loss: 2.35861(2.09855, 0.00075)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [10][499/3349] Elapsed 0m 51s (remain 4m 51s) Loss: 0.00118(0.00113)\n",
      "Epoch [10][999/3349] Elapsed 1m 40s (remain 3m 56s) Loss: 0.00132(0.00114)\n",
      "Epoch [10][1499/3349] Elapsed 2m 29s (remain 3m 4s) Loss: 0.00135(0.00114)\n",
      "Epoch [10][1999/3349] Elapsed 3m 19s (remain 2m 14s) Loss: 0.00113(0.00114)\n",
      "Epoch [10][2499/3349] Elapsed 4m 10s (remain 1m 24s) Loss: 0.00112(0.00113)\n",
      "Epoch [10][2999/3349] Elapsed 5m 0s (remain 0m 34s) Loss: 0.00109(0.00113)\n",
      "[DEBUG] train_score: 0.8010 eval_score: 0.6352\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 10, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [11][499/1733] Elapsed 4m 53s (remain 12m 3s) Loss: 1.88746(1.95214, 0.00060)\n",
      "Epoch [11][999/1733] Elapsed 9m 46s (remain 7m 10s) Loss: 1.72786(1.97169, 0.00055)\n",
      "Epoch [11][1499/1733] Elapsed 14m 42s (remain 2m 17s) Loss: 2.30015(1.99185, 0.00074)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [11][499/3349] Elapsed 0m 48s (remain 4m 36s) Loss: 0.00128(0.00117)\n",
      "Epoch [11][999/3349] Elapsed 1m 37s (remain 3m 49s) Loss: 0.00150(0.00117)\n",
      "Epoch [11][1499/3349] Elapsed 2m 28s (remain 3m 3s) Loss: 0.00157(0.00116)\n",
      "Epoch [11][1999/3349] Elapsed 3m 18s (remain 2m 14s) Loss: 0.00133(0.00117)\n",
      "Epoch [11][2499/3349] Elapsed 4m 10s (remain 1m 24s) Loss: 0.00113(0.00117)\n",
      "Epoch [11][2999/3349] Elapsed 5m 0s (remain 0m 34s) Loss: 0.00127(0.00117)\n",
      "[DEBUG] train_score: 0.8181 eval_score: 0.6346\n",
      "\n",
      "Epoch: 11. Reducing Learning Rate from 0.0005315625458024442 to 0.00039867189479991794\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 11, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [12][499/1733] Elapsed 4m 56s (remain 12m 10s) Loss: 1.69770(1.83524, 0.00054)\n",
      "Epoch [12][999/1733] Elapsed 9m 52s (remain 7m 14s) Loss: 1.90120(1.84599, 0.00061)\n",
      "Epoch [12][1499/1733] Elapsed 14m 44s (remain 2m 17s) Loss: 2.03942(1.85732, 0.00065)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [12][499/3349] Elapsed 0m 50s (remain 4m 45s) Loss: 0.00096(0.00119)\n",
      "Epoch [12][999/3349] Elapsed 1m 40s (remain 3m 56s) Loss: 0.00099(0.00120)\n",
      "Epoch [12][1499/3349] Elapsed 2m 28s (remain 3m 3s) Loss: 0.00085(0.00120)\n",
      "Epoch [12][1999/3349] Elapsed 3m 18s (remain 2m 13s) Loss: 0.00126(0.00120)\n",
      "Epoch [12][2499/3349] Elapsed 4m 8s (remain 1m 24s) Loss: 0.00093(0.00120)\n",
      "Epoch [12][2999/3349] Elapsed 4m 56s (remain 0m 34s) Loss: 0.00117(0.00120)\n",
      "[DEBUG] train_score: 0.8401 eval_score: 0.6335\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 12, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [13][499/1733] Elapsed 4m 50s (remain 11m 56s) Loss: 1.60406(1.73639, 0.00051)\n",
      "Epoch [13][999/1733] Elapsed 9m 43s (remain 7m 7s) Loss: 1.73791(1.75503, 0.00056)\n",
      "Epoch [13][1499/1733] Elapsed 14m 34s (remain 2m 15s) Loss: 1.65613(1.77125, 0.00053)\n",
      "[DEBUG] Evaluation Start\n",
      "[DEBUG] total eval data len: 214354\n",
      "[DEBUG] eval data loader len: 3349\n",
      "Epoch [13][499/3349] Elapsed 0m 50s (remain 4m 47s) Loss: 0.00124(0.00123)\n",
      "Epoch [13][999/3349] Elapsed 1m 41s (remain 3m 59s) Loss: 0.00108(0.00123)\n",
      "Epoch [13][1499/3349] Elapsed 2m 32s (remain 3m 7s) Loss: 0.00104(0.00122)\n",
      "Epoch [13][1999/3349] Elapsed 3m 22s (remain 2m 16s) Loss: 0.00137(0.00122)\n",
      "Epoch [13][2499/3349] Elapsed 4m 11s (remain 1m 25s) Loss: 0.00121(0.00122)\n",
      "Epoch [13][2999/3349] Elapsed 5m 0s (remain 0m 34s) Loss: 0.00143(0.00122)\n",
      "[DEBUG] train_score: 0.8525 eval_score: 0.6324\n",
      "\n",
      "Epoch: 13. Reducing Learning Rate from 0.00039867189479991794 to 0.0002990039065480232\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DEBUG] epoch 13, number of steps: 1733\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda python3 main.py --config config/butd_vqa.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP27nAUwJL6QTNEOS1HlcdF",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
